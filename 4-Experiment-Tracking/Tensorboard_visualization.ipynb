{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975ea8f8-d6c0-4090-b3be-68bba3e572f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"/Users/arjunlfc/Documents/workspace/_mlmodels/\")\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "from utils import data_setup, training\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1825774-5fb9-428d-8354-44b8238915b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'mps'\n",
    "    return 'cpu'\n",
    "\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = get_device()\n",
    "set_seeds()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6313c-b9aa-4dca-8bb6-4627ce519e4e",
   "metadata": {},
   "source": [
    "### Intro to Tracking Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1834b11-d507-4ab4-a492-f060711e5d77",
   "metadata": {},
   "source": [
    "There are as many different ways to track machine learning experiments as there are experiments to run. \n",
    "- TensorBoard: Extensions built into PyTorch, widely recognized and used, easily scales.\n",
    "- Weights & Biases: install wandb, make an account, Incredible user experience, make experiments public, tracks almost anything.\n",
    "- MLFlow: install mlflow and start tracking, Fully open-source MLOps lifecycle management, many integrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1a8d1-3aad-4b9e-ac5b-aa19e229cede",
   "metadata": {},
   "source": [
    "## Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ffcdf01-25a3-4615-9891-38eaa2924e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../2-NLP-CV-Basics/datasets/pizza_steak_sushi directory exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../2-NLP-CV-Basics/datasets/pizza_steak_sushi/train',\n",
       " '../2-NLP-CV-Basics/datasets/pizza_steak_sushi/test')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def download_data(dir_path, filename):\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(dir_path)\n",
    "    image_path = data_path / filename\n",
    "    \n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if image_path.is_dir():\n",
    "        print(f\"{image_path} directory exists.\")\n",
    "    else:\n",
    "        print(f\"Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download pizza, steak, sushi data\n",
    "        with open(data_path / f\"{filename}.zip\", \"wb\") as f:\n",
    "            request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "            print(\"Downloading pizza, steak, sushi data...\")\n",
    "            f.write(request.content)\n",
    "    \n",
    "        # Unzip pizza, steak, sushi data\n",
    "        with zipfile.ZipFile(data_path / f\"{filename}.zip\", \"r\") as zip_ref:\n",
    "            print(\"Unzipping pizza, steak, sushi data...\") \n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "DATASET_PATH=\"../2-NLP-CV-Basics/datasets/\"\n",
    "FILENAME=\"pizza_steak_sushi\"\n",
    "download_data(DATASET_PATH, FILENAME)\n",
    "\n",
    "# Setup train and testing paths\n",
    "train_dir = f\"{DATASET_PATH}{FILENAME}/train\"\n",
    "test_dir = f\"{DATASET_PATH}{FILENAME}/test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd630c91-f77b-4f4b-aa42-cdae2591fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x10a9149a0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x10aa65b80>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup pretrained weights (plenty of these available in torchvision.models)\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
    "automatic_transforms = weights.transforms() \n",
    "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=automatic_transforms, # use automatic created transforms\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44cbb7f-eed0-41df-a5c1-53013b26733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Download the pretrained weights for EfficientNet_B0\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # NEW in torchvision 0.13, \"DEFAULT\" means \"best weights available\"\n",
    "    \n",
    "    # Setup the model with the pretrained weights and send it to the target device\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "    \n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Since we're creating a new layer with random weights (torch.nn.Linear), \n",
    "    # let's set the seeds\n",
    "    set_seeds() \n",
    "    \n",
    "    # Update the classifier head to suit our problem\n",
    "    model.classifier = torch.nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, \n",
    "                  out_features=len(class_names),\n",
    "                  bias=True).to(device))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1545b-b6fa-4fb8-9dd4-8bca992f2627",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We can use PyTorch's `torch.utils.tensorboard.SummaryWriter()` class to save various parts of our model's training progress to file. The default location for log_dir is under runs/CURRENT_DATETIME_HOSTNAME, where the HOSTNAME is the name of your computer. But of course, you can change where your experiments are tracked (the filename is as customisable as you'd like). The outputs of the SummaryWriter() are saved in TensorBoard format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba14e05-26c2-4b48-9bee-f1179e08a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer(experiment_name: str, \n",
    "                  model_name: str, \n",
    "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
    "\n",
    "    Example usage:\n",
    "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
    "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb2\",\n",
    "                               extra=\"5_epochs\")\n",
    "        # The above is the same as:\n",
    "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
    "\n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "        \n",
    "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf0427c-08ad-42ae-ae3f-f4dca3081f73",
   "metadata": {},
   "source": [
    "We'll add the ability for our train() function to log our model's training and test loss and accuracy values. We can do this with writer.add_scalars(main_tag, tag_scalar_dict), where:\n",
    "- main_tag (string) - the name for the scalars being tracked (e.g. \"Accuracy\")\n",
    "- tag_scalar_dict (dict) - a dictionary of the values being tracked (e.g. {\"train_loss\": 0.3454})\n",
    "\n",
    "Once we've finished tracking values, we'll call writer.close() to tell the writer to stop looking for values to track.\n",
    "The `torch.utils.tensorboard.SummaryWriter()` class also has many different methods to track different things about your model/data, such as `add_graph()` which tracks the computation graph of your model. For more options, check the SummaryWriter() documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a012fe17-f7a9-4a04-801f-8d145c6e8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "          writer        \n",
    "         ):\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = training.train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = training.test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        if writer:\n",
    "            # Add loss results to SummaryWriter\n",
    "            writer.add_scalars(main_tag=\"Loss\", \n",
    "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                                \"test_loss\": test_loss},\n",
    "                               global_step=epoch)\n",
    "    \n",
    "            # Add accuracy results to SummaryWriter\n",
    "            writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                                \"test_acc\": test_acc}, \n",
    "                               global_step=epoch)\n",
    "            \n",
    "            # Track the PyTorch model architecture\n",
    "            writer.add_graph(model=model, \n",
    "                             # Pass in an example input\n",
    "                             input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "        \n",
    "            writer.close()\n",
    "            \n",
    "            \n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd9817-036f-42bc-b867-fc35e5cf75d4",
   "metadata": {},
   "source": [
    "### Demo Experiment and Tensorboard Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f1ffa2-5d83-4f1e-a358-8e95fc60cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: runs/2024-11-04/1/efficient_net...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7075ea3abd324548850a3ee339ed9140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.0175 | train_acc: 0.5078 | test_loss: 0.3972 | test_acc: 0.8561\n",
      "Epoch: 2 | train_loss: 0.7793 | train_acc: 0.7148 | test_loss: 0.2660 | test_acc: 0.9384\n",
      "Epoch: 3 | train_loss: 0.6636 | train_acc: 0.7617 | test_loss: 0.4326 | test_acc: 0.7737\n",
      "Epoch: 4 | train_loss: 0.4103 | train_acc: 0.8008 | test_loss: 0.3452 | test_acc: 0.8456\n",
      "Epoch: 5 | train_loss: 0.3308 | train_acc: 0.8711 | test_loss: 0.7270 | test_acc: 0.7131\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model1 = get_model()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "\n",
    "writer = create_writer(experiment_name=\"1\", model_name=\"efficient_net\")\n",
    "training_results = train(model1, train_dataloader, test_dataloader, optimizer, loss_fn, 5, device, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b868b5d0-9aef-4f8c-bc9f-56608c12671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0889f5a-832a-4d86-afac-5189a19a49bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
