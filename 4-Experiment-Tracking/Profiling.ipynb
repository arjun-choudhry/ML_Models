{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "065f7074-6386-4008-b27d-84d9bea813d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from triton.testing import do_bench\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "604a7b53-d397-4240-87bc-2f28521cf4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TORCH_COMPILE_DEBUG'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345b800-0d2e-4952-8aa0-7e3b1b50e148",
   "metadata": {},
   "source": [
    "## Creating a basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3993acb2-6536-431f-9ef4-3799fa79f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_modified(nn.Module):\n",
    "    \"\"\"\n",
    "    Added in a squared to the relu function so as to see the optimization in action\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_features=1, out_features=5)\n",
    "        self.l2 = nn.Linear(in_features=5, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x).relu() ** 2\n",
    "        return self.l2(x).relu() ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5ff2165-baf4-4ce8-b079-2c04942802a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "in_data = torch.arange(0.0,100.0,2).to(device).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eca443-55b1-4a5e-9650-46f91ed56ea0",
   "metadata": {},
   "source": [
    "## Pytorch Profiler\n",
    "PyTorch profiler is enabled through the context manager and accepts a number of parameters, some of the most useful are:\n",
    "\n",
    "- activities - a list of activities to profile:\n",
    "     - ProfilerActivity.CPU - PyTorch operators, TorchScript functions and user-defined code labels (see record_function below);\n",
    "     - ProfilerActivity.CUDA - on-device CUDA kernels;\n",
    "     - ProfilerActivity.XPU - on-device XPU kernels;\n",
    "\n",
    "- record_shapes - whether to record shapes of the operator inputs;\n",
    "- profile_memory - whether to report amount of memory consumed by modelâ€™s Tensors;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0cf372-cfe3-4913-a0b0-1ae32b8c92bc",
   "metadata": {},
   "source": [
    "#### Comparing running on cpu v/s mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2707644-0941-40ad-80ce-38648ad52abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "in_data = torch.arange(0.0,100.0,2).to(device).unsqueeze(dim=1)\n",
    "model = MLP_modified().to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(in_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a048ed-f6ba-4686-8414-216a9d6489fa",
   "metadata": {},
   "source": [
    "Note that we can use record_function context manager to label arbitrary code ranges with user provided names (model_inference is used as a label in the example above). Profiler allows one to check which operators were called during the execution of a code range wrapped with a profiler context manager. If multiple profiler ranges are active at the same time (e.g. in parallel PyTorch threads), each profiling context manager tracks only the operators of its corresponding range. Profiler also automatically profiles the asynchronous tasks launched with torch.jit._fork and (in case of a backward pass) the backward pass operators launched with backward() call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c81b85d-8359-49e3-a98a-7623dcfee7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              model_inference        15.63%       5.346ms       100.00%      34.210ms      34.210ms             1  \n",
      "                 aten::linear        68.72%      23.510ms        68.74%      23.516ms      11.758ms             2  \n",
      "                    aten::pow         7.04%       2.410ms         9.80%       3.354ms       1.677ms             2  \n",
      "                   aten::relu         5.81%       1.986ms         5.83%       1.994ms     997.061us             2  \n",
      "                   aten::item         1.88%     644.291us         2.76%     942.957us     471.479us             2  \n",
      "    aten::_local_scalar_dense         0.87%     298.666us         0.87%     298.666us     149.333us             2  \n",
      "             aten::empty_like         0.01%       3.416us         0.02%       7.709us       3.855us             2  \n",
      "                  aten::empty         0.02%       5.500us         0.02%       5.500us       2.750us             2  \n",
      "          aten::empty_strided         0.01%       4.293us         0.01%       4.293us       2.147us             2  \n",
      "            aten::result_type         0.00%       0.791us         0.00%       0.791us       0.395us             2  \n",
      "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 34.210ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8ac87-286e-4bb1-8231-2c6dfa600f96",
   "metadata": {},
   "source": [
    "Note the difference between self cpu time and cpu time - operators can call other operators, self cpu time excludes time spent in children operator calls, while total cpu time includes it. You can choose to sort by the self cpu time by passing sort_by=\"self_cpu_time_total\" into the table call. To get a finer granularity of results and include operator input shapes, pass group_by_input_shape=True (note: this requires running the profiler with record_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c26cd804-f6da-4f7b-bcd9-da5cba8332a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "       model_inference         4.93%     535.875us       100.00%      10.878ms      10.878ms             1  \n",
      "          aten::linear         7.77%     845.667us        75.39%       8.200ms       4.100ms             2  \n",
      "           aten::addmm        33.38%       3.631ms        40.68%       4.425ms       2.213ms             2  \n",
      "               aten::t        25.28%       2.749ms        26.93%       2.930ms       1.465ms             2  \n",
      "            aten::relu         4.70%     511.043us        16.41%       1.785ms     892.438us             2  \n",
      "       aten::clamp_min        11.71%       1.274ms        11.71%       1.274ms     636.916us             2  \n",
      "           aten::copy_         4.61%     501.541us         4.61%     501.541us     250.771us             2  \n",
      "             aten::pow         3.26%     355.044us         3.28%     356.751us     178.375us             2  \n",
      "    aten::resolve_conj         2.63%     286.457us         2.63%     286.457us      71.614us             4  \n",
      "       aten::transpose         1.61%     175.084us         1.66%     180.084us      90.042us             2  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 10.878ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "in_data = torch.arange(0.0,100.0,2).to(device).unsqueeze(dim=1)\n",
    "model = MLP_modified().to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(in_data)\n",
    "        \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14541a0a-656d-45c9-9a69-379793390c2e",
   "metadata": {},
   "source": [
    "#### Memory Consumption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "112c680d-0211-49c2-a016-0ff21a9ea8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "          aten::linear         6.96%      36.333us        65.79%     343.199us     171.599us       1.17 Kb           0 b             2  \n",
      "           aten::addmm        28.92%     150.871us        36.01%     187.828us      93.914us       1.17 Kb       1.17 Kb             2  \n",
      "            aten::relu         3.63%      18.957us        10.60%      55.290us      27.645us       1.17 Kb           0 b             2  \n",
      "       aten::clamp_min         6.96%      36.333us         6.96%      36.333us      18.167us       1.17 Kb       1.17 Kb             2  \n",
      "             aten::pow        22.92%     119.581us        23.61%     123.163us      61.582us       1.17 Kb       1.17 Kb             2  \n",
      "               aten::t        13.95%      72.790us        22.82%     119.038us      59.519us           0 b           0 b             2  \n",
      "       aten::transpose         7.28%      37.998us         8.87%      46.248us      23.124us           0 b           0 b             2  \n",
      "      aten::as_strided         2.16%      11.250us         2.16%      11.250us       2.812us           0 b           0 b             4  \n",
      "          aten::expand         1.24%       6.458us         1.81%       9.458us       4.729us           0 b           0 b             2  \n",
      "           aten::copy_         5.14%      26.832us         5.14%      26.832us      13.416us           0 b           0 b             2  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 521.652us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLP_modified().to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "    model(in_data)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fd614-b95e-4809-8d0c-a9d9d1a2b184",
   "metadata": {},
   "source": [
    "#### Tracing Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f98d5081-dc38-411e-a7e6-fc0342ef2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_modified().to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "    model(in_data)\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228cc6d-1687-4785-b6f9-2c5181e62cc3",
   "metadata": {},
   "source": [
    "You can examine the sequence of profiled operators and CUDA/XPU kernels in Chrome trace viewer (chrome://tracing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316b252-5ddb-4e4a-8ca4-4487199bb072",
   "metadata": {},
   "source": [
    "#### Examining stack traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "992a4649-8fa5-47c3-9878-800939e7208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "          aten::linear         9.61%      41.212us        79.98%     343.017us     171.508us             2  \n",
      "           aten::addmm        36.48%     156.466us        41.34%     177.299us      88.649us             2  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 428.857us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLP_modified().to(device)\n",
    "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True, with_stack=True) as prof:\n",
    "    model(in_data)\n",
    "\n",
    "# Print aggregated stats\n",
    "print(prof.key_averages(group_by_stack_n=5).table(sort_by='cpu_time_total', row_limit=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bddaca-d5a5-41a6-80d0-c7accf1c9d1b",
   "metadata": {},
   "source": [
    "#### Using profiler to analyse long-running jobs\n",
    "\n",
    "Profiler assumes that the long-running job is composed of steps, numbered starting from zero. The example above defines the following sequence of actions for the profiler:\n",
    "\n",
    "Parameter skip_first tells profiler that it should ignore the first 10 steps (default value of skip_first is zero);\n",
    "\n",
    "After the first skip_first steps, profiler starts executing profiler cycles;\n",
    "\n",
    "Each cycle consists of three phases:\n",
    "\n",
    "- idling (wait=5 steps), during this phase profiler is not active;\n",
    "- warming up (warmup=1 steps), during this phase profiler starts tracing, but the results are discarded; this phase is used to discard the samples obtained by the profiler at the beginning of the trace since they are usually skewed by an extra overhead;\n",
    "- active tracing (active=3 steps), during this phase profiler traces and records data;\n",
    "\n",
    "An optional repeat parameter specifies an upper bound on the number of cycles. By default (zero value), profiler will execute cycles as long as the job runs.\n",
    "\n",
    "Thus, in the example above, profiler will skip the first 15 steps, spend the next step on the warm up, actively record the next 3 steps, skip another 5 steps, spend the next step on the warm up, actively record another 3 steps. Since the repeat=2 parameter value is specified, the profiler will stop the recording after the first two cycles.\n",
    "\n",
    "At the end of each cycle profiler calls the specified on_trace_ready function and passes itself as an argument. This function is used to process the new trace - either by obtaining the table output or by saving the output on disk as a trace file.\n",
    "\n",
    "To send the signal to the profiler that the next step has started, call prof.step() function. The current profiler step is stored in prof.step_num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b83fdcc4-88f6-4ee0-9933-e5c46a48cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         ProfilerStep*        53.63%     165.377us       100.00%     308.340us     102.780us             3  \n",
      "           aten::addmm        14.89%      45.899us        20.53%      63.312us      10.552us             6  \n",
      "               aten::t         7.17%      22.122us         9.19%      28.329us       4.721us             6  \n",
      "       aten::clamp_min         6.46%      19.913us         6.46%      19.913us       3.319us             6  \n",
      "             aten::pow         4.86%      14.997us         5.35%      16.497us       2.750us             6  \n",
      "           aten::copy_         3.82%      11.789us         3.82%      11.789us       1.965us             6  \n",
      "            aten::relu         2.93%       9.038us         9.39%      28.951us       4.825us             6  \n",
      "          aten::linear         1.91%       5.874us        31.63%      97.515us      16.252us             6  \n",
      "      aten::as_strided         1.43%       4.414us         1.43%       4.414us       0.368us            12  \n",
      "       aten::transpose         1.23%       3.793us         2.01%       6.207us       1.034us             6  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 308.340us\n",
      "\n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "           aten::addmm        35.94%     201.273us        45.60%     255.364us      42.561us             6  \n",
      "         ProfilerStep*        34.36%     192.396us       100.00%     559.982us     186.661us             3  \n",
      "               aten::t         9.45%      52.924us        10.45%      58.508us       9.751us             6  \n",
      "           aten::copy_         8.66%      48.507us         8.66%      48.507us       8.084us             6  \n",
      "       aten::clamp_min         3.94%      22.087us         3.94%      22.087us       3.681us             6  \n",
      "             aten::pow         2.26%      12.630us         2.49%      13.919us       2.320us             6  \n",
      "            aten::relu         2.08%      11.667us         6.03%      33.754us       5.626us             6  \n",
      "          aten::linear         1.08%       6.041us        57.13%     319.913us      53.319us             6  \n",
      "      aten::as_strided         0.71%       3.956us         0.71%       3.956us       0.330us            12  \n",
      "       aten::transpose         0.64%       3.584us         1.00%       5.584us       0.931us             6  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 559.982us\n",
      "\n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         ProfilerStep*        61.77%     108.539us       100.00%     175.711us      58.570us             3  \n",
      "           aten::addmm        10.89%      19.138us        16.09%      28.269us       4.712us             6  \n",
      "             aten::pow         5.29%       9.297us         5.84%      10.257us       1.709us             6  \n",
      "               aten::t         5.05%       8.882us         7.45%      13.091us       2.182us             6  \n",
      "       aten::clamp_min         3.37%       5.921us         3.37%       5.921us       0.987us             6  \n",
      "            aten::relu         3.30%       5.796us         6.67%      11.717us       1.953us             6  \n",
      "           aten::copy_         3.25%       5.713us         3.25%       5.713us       0.952us             6  \n",
      "          aten::linear         2.18%       3.838us        25.72%      45.198us       7.533us             6  \n",
      "       aten::transpose         1.52%       2.665us         2.40%       4.209us       0.702us             6  \n",
      "      aten::as_strided         1.47%       2.586us         1.47%       2.586us       0.215us            12  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 175.711us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "sort_by_keyword = \"self_\" + device + \"_time_total\"\n",
    "\n",
    "def trace_handler(p):\n",
    "    output = p.key_averages().table(sort_by=sort_by_keyword, row_limit=10)\n",
    "    print(output)\n",
    "    p.export_chrome_trace(\"/tmp/trace_\" + str(p.step_num) + \".json\")\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3),\n",
    "    on_trace_ready=trace_handler\n",
    ") as p:\n",
    "    for idx in range(16):\n",
    "        model(in_data)\n",
    "        p.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536a94d-7e24-49b2-a0a5-cb78fb48b1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
